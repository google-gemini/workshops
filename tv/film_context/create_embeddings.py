"""Create embeddings from comprehensive film context documents

Takes the rich film documents generated by data_gatherer.py and converts them
into embeddings suitable for semantic search and AI commentary.
"""

import json
import sys
from pathlib import Path

from google import genai
from google.genai import types


def chunk_text(text, chunk_size=1000, overlap=200):
    """Split text into overlapping chunks"""
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)
        start = end - overlap
    return chunks


async def create_film_embeddings(context_file: str, output_file: str = None):
    """Create embeddings from film context document
    
    Args:
        context_file: Path to the film context document
        output_file: Optional output file path (auto-generated if not provided)
    """
    
    # Validate input file
    context_path = Path(context_file)
    if not context_path.exists():
        raise FileNotFoundError(f"Context file not found: {context_file}")
    
    # Generate output filename if not provided
    if not output_file:
        output_file = context_path.stem + "_embeddings.json"
    
    print(f"ğŸ¬ Creating embeddings from: {context_file}")
    print(f"ğŸ“„ Output file: {output_file}")
    print("=" * 60)
    
    # Initialize Gemini client
    client = genai.Client()
    
    # Read film context document
    print("ğŸ“– Reading film context document...")
    with open(context_file, "r", encoding="utf-8") as f:
        text = f.read()
    
    print(f"âœ… Loaded document: {len(text):,} characters")
    
    # Split into chunks
    print("âœ‚ï¸ Chunking document...")
    chunks = chunk_text(text)
    print(f"âœ… Created {len(chunks)} chunks")
    
    # Create embeddings
    print("\nğŸ”® Creating embeddings...")
    embeddings_data = []
    
    for i, chunk in enumerate(chunks):
        print(f"Processing chunk {i+1}/{len(chunks)}")
        
        try:
            response = client.models.embed_content(
                model="gemini-embedding-001",
                contents=chunk,
                config=types.EmbedContentConfig(task_type="retrieval_document"),
            )
            
            embeddings_data.append({
                "chunk_id": i,
                "text": chunk,
                "embedding": response.embeddings[0].values
            })
            
        except Exception as e:
            print(f"âŒ Error processing chunk {i+1}: {e}")
            # Continue with other chunks
            continue
    
    # Save embeddings to file
    print(f"\nğŸ’¾ Saving embeddings...")
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(embeddings_data, f)
    
    print(f"âœ… Embeddings saved to: {output_file}")
    print(f"ğŸ“Š Final stats:")
    print(f"   Total chunks: {len(chunks)}")
    print(f"   Successful embeddings: {len(embeddings_data)}")
    print(f"   Document coverage: {len(embeddings_data)/len(chunks)*100:.1f}%")
    
    return output_file


if __name__ == "__main__":
    import asyncio
    
    async def main():
        if len(sys.argv) < 2:
            print("Usage: python create_embeddings.py 'context_file.txt' [output_file.json]")
            print("Example: python create_embeddings.py 'The_Big_Sleep_1946_context.txt'")
            sys.exit(1)
        
        context_file = sys.argv[1]
        output_file = sys.argv[2] if len(sys.argv) > 2 else None
        
        try:
            result_file = await create_film_embeddings(context_file, output_file)
            print(f"\nğŸ‰ Success! Film embeddings created.")
            print(f"ğŸ“„ Ready for semantic search: {result_file}")
            
        except Exception as e:
            print(f"âŒ Error: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
    
    asyncio.run(main())
